# Neural Caption Generator
* Tensorflow implementation of "Show and Tell" http://arxiv.org/abs/1411.4555
 * Borrowed some code and ideas from Andrej Karpathy's NeuralTalk.
* You need flickr30k data (images and annotations)
 
### Code
* make_flickr_dataset.py : Extracting feats of flickr30k images, and save them in './data/feats.npy' 
* model.py : TensorFlow Version
 
#### Usage
* Flickr30k Dataset Download
* Extract VGG Featues of Flicker30k images (make_flickr_dataset.py)
* Train: run train() in  model.py
* Test: run test() or test_tf() in model.py
 * parameters: VGG FC7 feature of test image, trained model path
 * Once you download Tensorflow VGG Net (one of the links below), you don't need Caffe when testing.

#### Downloading data/trained model
* Extraced FC7 data: [download](https://drive.google.com/file/d/0B5o40yxdA9PqTnJuWGVkcFlqcG8/view?usp=sharing)
 * This is used in train() function in model.py. You can skip feature extraction part by using this.
* Pretrained model [download](https://drive.google.com/file/d/0B5o40yxdA9PqeW4wY0wwZXhrZkE/view?usp=sharing)
 * This is used in test() and test_tf() in model.py. If you do not have time for training, or if you just want to check out captioning, download and test the model.
* Tensorflow VGG net [download](https://drive.google.com/file/d/0B5o40yxdA9PqSGtVODN0UUlaWTg/view?usp=sharing)
 * This file is used in test_tf() in model.py
* Along with the files above, you might want to download flickr30k annotation data from [link](http://shannon.cs.illinois.edu/DenotationGraph/) 

![alt tag](https://github.com/jazzsaxmafia/show_and_tell.tensorflow/blob/master/result.jpg)

### License
* BSD license


-----
# Automatic Semantic Annotation of Images (ASAI) code

This is source code for generating automatic semantic of images in the form of sentence based on image pixels and text. Because the system needs images and text input to generate image annotations, the image should come from an article where there is a text that surround the images, such as news web sites.

## Preparing Dependencies
This guide is intended for preparing the dependencies in linux environment.
* Install Anaconda 3 version 4.2.0 (open the installer and follow the instructions)
```shell
sh Anaconda3-4.2.0-Linux-x86_64.sh
```
* Install opencv3, keras, dask
```shell
conda install -c menpo opencv3
conda install keras
pip install dask --upgrade
```
* Install tensorflow 0.12.1
```shell
wget https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl
pip3 install tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl
```
* Install nltk dependencies
```shell
python -c "import nltk;nltk.download('popular')"
```


python asai_train.py --num_word_count_threshold=5 --dim_embed=96 --dim_hidden=96 --batch_size=24

-------

1. Install anaconda 3
2. install mkl
2. Install tensorflow
3. To train a model of asai, run the program asai-train with parameters.
4. To test a model, run the program

Note:
ASAI can be run with cpu but it will require a lot of time. It requires GPU to be fast

asai needs an image features generated by a cnn. we used cnn from vgg.
